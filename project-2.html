<!-- Metadata -->
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Elevator</title>
  <link rel="stylesheet" href="css/global.css" />
  <link rel="stylesheet" href="css/project-page.css" />

  <!-- JavaScript to run model -->
  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>

  <!-- Extra CSS styling for model testing -->
  <style>
    .demo-section {
    display: flex;
    align-items: center;
    justify-content: center;
    gap: 2rem;
    height: 500px;
    padding: 2rem;
    box-sizing: border-box;
    }

    .upload-side {
    display: flex;
    align-items: center;
    justify-content: center;
    flex: 1;
    }

    .upload-wrapper {
    display: flex;
    flex-direction: column;
    align-items: center;
    justify-content: center;
    }

    #upload {
    margin-bottom: 1rem;
    cursor: pointer;
    }

    #prediction {
    font-weight: bold;
    text-align: center;
    }

    .preview-side {
    display: flex;
    align-items: center;
    flex: 1;
    }

    canvas {
    border: 1px solid #000;
    width: auto;
    height: 300px;
    image-rendering: pixelated;
    }

    .description {
    flex: 1 1 45%;
    font-size: 1rem;
    line-height: 1.6;
    }
  </style>

  <!-- Header -->
  </head>
  <body>
    <header>
      <h1>Traffic</h1>
      <nav>
        <ul>
          <li><a href="portfolio.html">Other Projects</a></li>
        </ul>
      </nav>
    </header>

  <div class="container">
    <section>
      
      <!-- Sliding carousel, images duplicated for seamless wraparound -->
      <div class="slider-wrapper">
        <div class="slider">
          <img class="slide" src="images/traffic-1.jpg" alt="Image 1">
          <img class="slide" src="images/traffic-2.jpg" alt="Image 2">
          <img class="slide" src="images/traffic-3.png" alt="Image 3">
          <img class="slide" src="images/traffic-4.png" alt="Image 4">
          <img class="slide" src="images/traffic-1.jpg" alt="Image 1 duplicate">
          <img class="slide" src="images/traffic-2.jpg" alt="Image 2 duplicate">
          <img class="slide" src="images/traffic-3.png" alt="Image 3 duplicate">
          <img class="slide" src="images/traffic-4.png" alt="Image 4 duplicate">
        </div>
      </div>

      <!-- Model demonstration -->
      <div class="demo-section">
        <div class="demo-box">
          <div class="upload-side">
            <div class="upload-wrapper">
              <input type="file" accept="image/*" id="upload" />
              <p id="prediction">Prediction will appear here.</p>
            </div>
          </div>
          <div class="preview-side">
            <canvas id="canvas" width="30" height="30"></canvas>
          </div>
        </div>
      
        <!-- Description-->
        <div class="description">
          <p>
            A Convolutional Neural Network (CNN) trained on the German Traffic Sign Recognition Benchmark (GTSRB) dataset. It is modeled after the LeNet CNN architecture and implemented using the PyTorch machine learning library. To test the model, upload an image!
          </p>
        </div>
      </div>
      
  </div>

  <!-- JavaScript for putting uploaded image through model and displaying results -->
  <script type="module">
    const CATEGORY_KEY = [
      "Speed Limit (20 km/h)", "Speed Limit (30 km/h)", "Speed Limit (50 km/h)", "Speed Limit (60 km/h)", "Speed Limit (70 km/h)", "Speed Limit (80 km/h)",
      "End Speed Limit (80 km/h)", "Speed Limit (100 km/h)", "Speed Limit (120 km/h)", "No Passing", "No Passing (Vehicles Heavier than 3.5 Metric Tons)",
      "Right of Way", "Priority Road", "Yield", "Stop", "No Vehicles",
      "No Vehicles Heavier than 3.5 Metric Tons", "No Entry", "Caution", "Watch Curve Left",
      "Watch Curve Right", "Double Curve", "Bumpy Road", "Slippery Road",
      "Road Narrows Right", "Road Work", "Traffic Signals", "Pedestrians",
      "Children Crossing", "Bicycles Crossing", "Ice/Snow", "Wild Animals Crossing",
      "End Speed/Passing Limit", "Turn Right Ahead", "Turn Left Ahead",
      "Ahead Only", "Straight or Right", "Straight or Left", "Keep Right",
      "Keep Left", "Roundabout", "End No Passing", "End No Passing (Vehicles Heavier than 3.5 Metric Tons)"
    ];

    const model = await ort.InferenceSession.create("model.onnx");

    document.getElementById("upload").addEventListener("change", async (event) => {
      const file = event.target.files[0];
      if (!file) return;

      const img = new Image();
      img.src = URL.createObjectURL(file);
      img.onload = async () => {
        const canvas = document.getElementById("canvas");
        const ctx = canvas.getContext("2d");
        ctx.drawImage(img, 0, 0, 30, 30);

        const imageData = ctx.getImageData(0, 0, 30, 30).data;
        const inputTensor = new Float32Array(1 * 3 * 30 * 30);

        for (let i = 0; i < 30 * 30; i++) {
          inputTensor[i] = imageData[i * 4] / 255.0;
          inputTensor[i + 900] = imageData[i * 4 + 1] / 255.0;
          inputTensor[i + 1800] = imageData[i * 4 + 2] / 255.0;
        }

        const tensor = new ort.Tensor("float32", inputTensor, [1, 3, 30, 30]);
        const results = await model.run({ input: tensor });
        const output = results.output.data;
        const prediction = output.indexOf(Math.max(...output));

        document.getElementById("prediction").textContent = `Prediction: ${CATEGORY_KEY[prediction]}`;
      };
    });
  </script>
</body>
</html>
