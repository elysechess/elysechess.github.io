<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Elevator</title>
  <link rel="stylesheet" href="css/global.css" />
  <link rel="stylesheet" href="css/project-page.css" />
  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
  <style>
    .demo-section {
      display: flex;
      align-items: center;     /* vertical alignment */
      justify-content: center; /* horizontal spacing */
      height: 500px;           /* or whatever height you want */
      gap: 2rem;
    }

    .demo-box {
    display: flex;
    height: 100%;                 /* full height of parent container */
    border: 1px solid #ccc;
    background: #f9f9f9;
    padding: 1rem;
    gap: 1rem;
    }

    .upload-area {
    display: flex;
    align-items: center;
    justify-content: center;
    flex: 1;
    }

    .upload-area input[type="file"] {
    cursor: pointer;
    }

    .preview-area {
    display: flex;
    flex-direction: column;
    align-items: center;
    justify-content: center;
    flex: 1;
    }

    canvas {
    border: 1px solid #000;
    width: auto;
    height: 100%;
    max-height: 300px;
    image-rendering: pixelated;
    }

    #prediction {
    font-weight: bold;
    margin-top: 1rem;
    text-align: center;
    }

  </style>
</head>
<body>
  <header>
    <h1>Traffic</h1>
    <nav>
      <ul>
        <li><a href="index.html">Home</a></li>
        <li><a href="portfolio.html">Other Projects</a></li>
      </ul>
    </nav>
  </header>

  <div class="container">
    <section>
      <!-- Image Slider Section -->
      <div class="slider-wrapper">
        <div class="slider">
          <img class="slide" src="images/traffic-1.jpg" alt="Image 1">
          <img class="slide" src="images/traffic-2.jpg" alt="Image 2">
          <img class="slide" src="images/traffic-3.png" alt="Image 3">
          <img class="slide" src="images/traffic-4.png" alt="Image 4">
          <img class="slide" src="images/traffic-1.jpg" alt="Image 1 duplicate">
          <img class="slide" src="images/traffic-2.jpg" alt="Image 2 duplicate">
          <img class="slide" src="images/traffic-3.png" alt="Image 3 duplicate">
          <img class="slide" src="images/traffic-4.png" alt="Image 4 duplicate">
        </div>
      </div>

      <div class="demo-section">
        <div class="demo-box">
          <input type="file" accept="image/*" id="upload" />
          <canvas id="canvas" width="30" height="30"></canvas>
          <p id="prediction">Prediction will appear here.</p>
        </div>
        <div class="description">
          <p>A Convolutional Neural Network (CNN) trained on the German Traffic Sign Recognition Benchmark (GTSRB) dataset. It is modeled after the LeNet CNN architecture and implemented using the PyTorch machine learning library. To test the model, upload an image!</p>
        </div>
      </div>
    </section>
  </div>

  <script type="module">
    const CATEGORY_KEY = [
      "Speed Limit (20 km/h)", "Speed Limit (30 km/h)", "Speed Limit (50 km/h)", "Speed Limit (60 km/h)", "Speed Limit (70 km/h)", "Speed Limit (80 km/h)",
      "End Speed Limit (80 km/h)", "Speed Limit (100 km/h)", "Speed Limit (120 km/h)", "No Passing", "No Passing (Vehicles Heavier than 3.5 Metric Tons)",
      "Right of Way", "Priority Road", "Yield", "Stop", "No Vehicles",
      "No Vehicles Heavier than 3.5 Metric Tons", "No Entry", "Caution", "Watch Curve Left",
      "Watch Curve Right", "Double Curve", "Bumpy Road", "Slippery Road",
      "Road Narrows Right", "Road Work", "Traffic Signals", "Pedestrians",
      "Children Crossing", "Bicycles Crossing", "Ice/Snow", "Wild Animals Crossing",
      "End Speed/Passing Limit", "Turn Right Ahead", "Turn Left Ahead",
      "Ahead Only", "Straight or Right", "Straight or Left", "Keep Right",
      "Keep Left", "Roundabout", "End No Passing", "End No Passing (Vehicles Heavier than 3.5 Metric Tons)"
    ];

    const model = await ort.InferenceSession.create("model.onnx");

    document.getElementById("upload").addEventListener("change", async (event) => {
      const file = event.target.files[0];
      if (!file) return;

      const img = new Image();
      img.src = URL.createObjectURL(file);
      img.onload = async () => {
        const canvas = document.getElementById("canvas");
        const ctx = canvas.getContext("2d");
        ctx.drawImage(img, 0, 0, 30, 30);

        const imageData = ctx.getImageData(0, 0, 30, 30).data;
        const inputTensor = new Float32Array(1 * 3 * 30 * 30);

        for (let i = 0; i < 30 * 30; i++) {
          inputTensor[i] = imageData[i * 4] / 255.0;
          inputTensor[i + 900] = imageData[i * 4 + 1] / 255.0;
          inputTensor[i + 1800] = imageData[i * 4 + 2] / 255.0;
        }

        const tensor = new ort.Tensor("float32", inputTensor, [1, 3, 30, 30]);
        const results = await model.run({ input: tensor });
        const output = results.output.data;
        const prediction = output.indexOf(Math.max(...output));

        document.getElementById("prediction").textContent = `Prediction: ${CATEGORY_KEY[prediction]}`;
      };
    });
  </script>
</body>
</html>
